<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>Chapter 3 – Probability Theory</title>

<style>
@import url('https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap');

body{
    margin:0;
    padding:0;
    font-family:'Poppins',sans-serif;
    background:linear-gradient(135deg,#667eea,#764ba2);
    display:flex;
    justify-content:center;
}

.container{
    width:90%;
    max-width:1100px;
    background:rgba(255,255,255,0.15);
    backdrop-filter:blur(12px);
    border-radius:20px;
    padding:40px;
    margin:40px 0;
    color:#fff;
}

h1{
    text-align:center;
    margin-bottom:30px;
}

h2{
    margin-top:35px;
    padding-left:12px;
    border-left:5px solid #ffd369;
}

h3{
    margin-top:20px;
}

p{
    line-height:1.8;
    margin-top:10px;
}

ul{
    margin-left:25px;
    margin-top:10px;
}

.formula{
    margin:15px 0;
    padding:14px;
    background:rgba(255,255,255,0.18);
    border-radius:10px;
    text-align:center;
    font-weight:600;
}

footer{
    text-align:center;
    margin-top:40px;
    font-size:13px;
    opacity:0.85;
}
</style>
</head>

<body>

<div class="container">

<h1>Chapter 3: Random Variables & Distributions</h1>

<!-- =============================== -->

<h2>Definition and Interpretation of Probability</h2>

<p>
Probability is used to measure how likely an event is to occur in situations involving uncertainty.
It helps in predicting outcomes when exact results cannot be determined in advance.
In engineering and data science, probability supports decision-making, system analysis,
and performance evaluation under uncertain conditions.
</p>

<h3>Mathematical Definition</h3>

<p>
The probability of an event is calculated by comparing the number of favorable outcomes
to the total number of possible outcomes when all outcomes are equally likely.
</p>

<div class="formula">
P(A) = Number of favorable outcomes / Total number of outcomes
</div>

<p>
The value of probability always lies between 0 and 1, where 0 indicates impossibility
and 1 indicates certainty.
</p>

<!-- =============================== -->

<h2>Interpretations of Probability</h2>

<h3>1. Classical Interpretation</h3>

<p>
This interpretation is applicable when the outcomes of an experiment are equally likely.
It is commonly used in theoretical problems such as tossing coins or rolling dice.
</p>

<div class="formula">
P(A) = n(A) / n(S)
</div>

<h3>2. Empirical Interpretation</h3>

<p>
Empirical probability is based on experimental data and long-run observations.
As the number of trials increases, the relative frequency of an event approaches its probability.
</p>

<div class="formula">
P(A) = lim (Number of times A occurs / Total trials)
</div>

<h3>3. Subjective Interpretation</h3>

<p>
Subjective probability depends on individual judgment and experience rather than experimental data.
It is often used when numerical data is unavailable, such as in forecasting or planning.
</p>

<!-- =============================== -->

<h2>Types of Events</h2>

<h3>Equally Likely Events</h3>

<p>
Events are equally likely when each possible outcome has the same chance of occurring.
This assumption simplifies probability calculations in many theoretical models.
</p>

<h3>Complementary Event</h3>

<p>
The complement of an event represents all outcomes where the event does not occur.
Knowing the probability of an event allows easy calculation of its complement.
</p>

<div class="formula">
P(A′) = 1 − P(A)
</div>

<h3>Mutually Exclusive Events</h3>

<p>
Two events are mutually exclusive if the occurrence of one event prevents the occurrence of the other.
Such events never overlap in the sample space.
</p>

<div class="formula">
P(A ∩ B) = 0
</div>

<h3>Independent Events</h3>

<p>
Events are independent when the occurrence of one event does not influence the probability
of another event.
</p>

<div class="formula">
P(A ∩ B) = P(A) × P(B)
</div>

<h3>Dependent Events</h3>

<p>
In dependent events, the outcome of one event changes the probability of another.
This situation commonly arises in experiments without replacement.
</p>

<div class="formula">
P(A ∩ B) = P(A) × P(B | A)
</div>

<!-- =============================== -->

<h2>Addition and Multiplication Rules</h2>

<h3>Addition Rule (Mutually Exclusive)</h3>

<p>
When two events cannot occur together, the probability of either event occurring
is the sum of their individual probabilities.
</p>

<div class="formula">
P(A ∪ B) = P(A) + P(B)
</div>

<h3>Addition Rule (Non-Mutually Exclusive)</h3>

<p>
If events can occur simultaneously, the probability of their intersection
must be subtracted to avoid double counting.
</p>

<div class="formula">
P(A ∪ B) = P(A) + P(B) − P(A ∩ B)
</div>

<h3>Multiplication Rule</h3>

<p>
The multiplication rule is used to find the probability that two events occur together,
depending on whether the events are independent or dependent.
</p>

<div class="formula">
P(A ∩ B) = P(A) × P(B)
</div>

<div class="formula">
P(A ∩ B) = P(A) × P(B | A)
</div>

<!-- =============================== -->

<h2>Conditional Probability</h2>

<p>
Conditional probability measures the likelihood of an event occurring given that
another related event has already occurred.
It reduces the sample space to relevant outcomes.
</p>

<div class="formula">
P(A | B) = P(A ∩ B) / P(B), P(B) ≠ 0
</div>

<p>
If the conditional probability of an event equals its original probability,
the events are considered independent.
</p>

<div class="formula">
P(A | B) = P(A)
</div>

<!-- =============================== -->

<h2>Bayes’ Theorem</h2>

<p>
Bayes’ Theorem provides a powerful method to revise probabilities when new evidence becomes available.
It is widely used in machine learning, diagnostics, and decision support systems.
</p>

<div class="formula">
P(A | B) = [ P(B | A) × P(A) ] / P(B)
</div>



<h3>Applications</h3>

<ul>
<li>Medical diagnosis</li>
<li>Machine learning</li>
<li>Spam filtering</li>
<li>Fault detection</li>
<li>Risk analysis</li>
</ul>

<footer>
Chapter 3 – Probability Theory | Engineering Statistics
</footer>

</div>
</body>
</html>
